La visión de la gerencia de área de auditoría digital corporativa según la Guía Metodológica de Auditoría Continua, Data y Analítica de Datos es ser la unidad referente de Auditoría Analítica Credicorp, a nivel internacional, la cual realiza auditorías de prevención y detección basada en la aplicación de Data & Analytics.
La misión de la gerencia de área de auditoría digital corporativa según la Guía Metodológica de Auditoría Continua, Data y Analítica de Datos es ser agentes de la transformación implementando y facilitando, en la División de Auditoría, la adopción de técnicas de auditoría basada en Data & Analytics.
El objetivo de la gerencia de área de auditoría digital corporativa según la Guía Metodológica de Auditoría Continua, Data y Analítica de Datos es construir un modelo de Auditoría Continua, Data & analytics, acorde a la realidad tecnológica del BCP, a partir del análisis y cohesión de las relaciones existentes entre los conceptos, paradigmas, estándares, metodologías y prácticas de Auditoría Continua.?
Los casos de uso de soluciones en auditoría digital corporativa según la Guía Metodológica de Auditoría Continua, Data y Analítica de Datos se definen tipos y subtipos de categorías para cada una de estas: (1) Pruebas Digitalizadas, (2) Advanced Analytics, (3) Soluciones de Data y (4) Soluciones de Soporte.
Las pruebas digitalizadas según la Guía Metodológica de Auditoría Continua, Data y Analítica de Datos son pruebas digitalizadas en herramientas Core del bancon el objetivo de analizar una revisión puntual en el proceso de auditoría, estas pueden ser CAATs en PL/SQL y  CAATs en Python.
Las CAATs en PL/SQL según la Guía Metodológica de Auditoría Continua, Data y Analítica de Datos son “Computer Assisted Audit Techniques”, estas son creadas con el fin de digitalizar una prueba operativa/manual de un proceso de auditoría en la herramienta PLSQL.
Las CAATs en Pythons según la Guía Metodológica de Auditoría Continua, Data y Analítica de Datos son “Computer Assisted Audit Techniques”, estas son creadas con el fin de digitalizar una prueba operativa/manual de un proceso de auditoría en la herramienta Python. 
Las  soluciones de advanced analytics a según la Guía Metodológica de Auditoría Continua, Data y Analítica son un conjunto integral de técnicas y métodos analíticos como Big Data, Inteligencia Artificial (IA), Machine Learning, etc que  permiten un mejor análisis predictivo/descriptivo y proporcionan información para describir y predecir proyectando eventos, comportamientos y tendencias futuros, estas pueden ser de enfoque cognitivo, descriptivo y predictivo.
Las soluciones advance analytics de enfoque cognitivo (OCR, Speech Analytics) según la Guía Metodológica de Auditoría Continua, Data y Analítica de Datos indican que la computación cognitiva es un software que trata de pensar y aprender imitando el funcionamiento del cerebro humano, se usan tecnologías como “Procesamiento de Lenguaje Natural” (NLP) y “Computer Vision” para poder transcribir documentos, audios, identificar anomalías, entre otros, dentro del proceso de auditoría.
Las soluciones advance analytics de enfoque descriptivo según la Guía Metodológica de Auditoría Continua, Data y Analítica de Datos indican los análisis y modelos descriptivos consisten en describir las tendencias claves en los datos existentes y observar las situaciones que conduzcan a nuevos hechos o alertas por inconsistencia dentro del proceso de auditoría.
Las soluciones advance analytics de enfoque predictivo según la Guía Metodológica de Auditoría Continua, Data y Analítica de Datos se basan en modelos predictivos, estos son un conjunto de técnicas que mediante los campos del Machine Learning: la recolección de datos históricos, el Big Data y el reconocimiento de patrones, pretende dar una predicción de resultados de comportamientos futuros dentro de las auditorías.
Las soluciones de data según la Guía Metodológica de Auditoría Continua, Data y Analítica de Datos son soluciones que Auditoría ofrece para automatizar procesos completos de una auditoría cuya automatización se encarga de procesar y transformar (ETL) las fuentes de información y construir y replicar el proceso auditado de inicio a fin, cabe resaltar que automatización se refiere al procesamiento y transformación de fuentes de información con el fin de construir y replicar el proceso auditado de inicio a fin (procesos end to end).
Las soluciones de soporte según la Guía Metodológica de Auditoría Continua, Data y Analítica de Datos son soluciones ágiles que Auditoría ofrece para responder a las necesidades del negocio, estas pueden ser: métricas, automatización de procesos de monitoreo, visualización de procesos.
El equipo de Auditoría Continua y Data Anlytics según la Guía Metodológica de Auditoría Continua, Data y Analítica de Datos está organizado de la siguiente manera: (1) Unidad de Data & Business Intelligence, compuesto por el Chapter de Data Analytics Fundamentals y Chapter Data Engineering (Automatización & Tech); y (2) Unidad de Advanced Analytics & Monitoreo Continuo, compuesto por el Chapter de Advanced Analytics y Chapter de Monitoreo Continuo
El objetivo del Manual de Gobierno de Modelos Analiticos de Auditoria es establecer el marco para el gobierno, metodologias, procedimientos, roles y responsabilidades en las areas de Auditoria Continua y Auditoria de Riesgos Corporativos que garantizar el adecuado desarrollo de los modelos analiticos desde su concepcion hasta su implementacion, asegurando la sostenibilidad y relevancia a lo largo del tiempo.
El alcance del Manual de Gobierno de Modelos Analiticos de Auditoria consiste en la distribucion de responsables y usuarios de los modelos analiticos dentro de la Division de Auditoria, siendo gestionado y actualizado por el Chapter de Advanced Analytics, este ultimo genera valor a traves del uso de datos, satisfaciendo las necesidades analiticas de la Division y creando herramientas analiticas  y modelos estadisticos para agregar valor al trabajo de auditoria, para ello se busca la integracion de roles clave como Product Owner, Project Manager, Data Scientist Leader, Business Expert y Data Engineer.
Los roles indicados en el Manual de Gobierno de Modelos Analiticos de Auditoria son cuatro: (1) Product Owner o dueño del producto, (2) Project Manager, (3) Data Scientiest Leader y (4) Data Engineer siendo el  equipo “Analytics” auto organizado y multidisciplinario, ya que eligen la mejor forma de llevar a cabo su trabajo y tienen todas las competencias necesarias, incluyendo cientificos de datos, expertos del area de negocio, expertos en base de datos y desarrollo de sistemas.
Las funciones del product owner o dueño del producto indicados en el Manual de Gobierno de Modelos Analíticos de Auditoría son las siguientes: ser el encargado de maximizar el valor del producto, definiendo el alcance del proyecto, guiando su desarrollo y asegurando la satisfaccion de la informacion generada para los interesados del negocio. Como experto en el area relevante, sus funciones incluyen definir el alcance y MVP del proyecto, seleccionar al business expert (auditor) para el equipo de desarrollo, aprobar variables en colaboracion con expertos del negocio y otros profesionales, coordinar con el area de negocio usuaria de la informacion y convocar a expertos para capacitar al equipo tecnico.
Las funciones del Project Manager indicados en el Manual de Gobierno de Modelos Analíticos de Auditoría son las siguientes:definir, planificar y supervisar proyectos, coordinando con las gerencias de area para abordar las necesidades analiticas, este rol es asumido por el Subgerente de la unidad de Advanced Analytics; actua actua como gestor, definiendo y aprobando la planificacion del proyecto, supervisando su desarrollo, invitando a expertos para capacitar al equipo tecnico y coordinando con el equipo de Analytics.
El rol del Project Manager indicado en el Manual de Gobierno de Modelos Analíticos de Auditoría son las siguientes:definir, planificar y supervisar proyectos, coordinando con las gerencias de area para abordar las necesidades analiticas, este rol es asumido por el Subgerente de la unidad de Advanced Analytics; actua actua como gestor, definiendo y aprobando la planificacion del proyecto, supervisando su desarrollo, invitando a expertos para capacitar al equipo tecnico y coordinando con el equipo de Analytics.
Las funciones del Data Scientist Leader indicados en el Manual de Gobierno de Modelos Analiticos de Auditorias son las siguientes: ser el profesional encargado de desarrollar productos, liderar y gestionar las tareas del equipo de desarrollo, sus responsabilidades incluyen la construccion de modelos analiticos, el uso de herramientas como R, Python, Hadoop, entre otras, y la gestion del Data Engineer y Business Expert; entre otras de sus funciones destacadas se encuentran la generacion y gestion del equipo de desarrollo, el apoyo en el planteo del enfoque analitico, la realizacion de analisis descriptivo, limpieza e imputacion de datos, creacion y calibracion de modelos analiticos, manipulacion de grandes volumenes de datos para generar informacion valiosa para el negocio, definicion de duracion y entregables de cada sprint, validacion y documentacion de modelos analiticos, mantenimiento continuo de los modelos generados y supervision del cumplimiento de la metodologia de desarrollo por parte del equipo.
Las principales funciones del Data Scientist Engineer indicados en el Manual de Gobierno de Modelos Analiticos de Auditorias son las siguientes: velar por la disponibilidad y calidad de los datos, crear variables para modelos y areas operativas, garantizar la seguridad e integridad del sistema, monitorear la carga de informacion para modelos de ciencia de datos, desarrollar sistemas adaptables, investigar nuevas tecnologias de software y arquitecturas analiticas, documentar variables utilizadas en modelos, construir y mantener estructuras de datos necesarias para implementar modelos, y emplear programas avanzados de analisis y metodos estadisticos para preparar datos en modelos predictivos y prescriptivos.
Las responsabilidades principales de un Data Engineer segun el Manual de Gobierno de Modelos Analiticos de Auditori incluyen velar por la disponibilidad y calidad de los datos, crear variables para modelos y areas operativas, garantizar la seguridad e integridad del sistema, monitorear la carga de informacion para modelos de ciencia de datos, desarrollar sistemas adaptables, investigar nuevas tecnologias de software y arquitecturas analiticas, documentar variables utilizadas en modelos, construir y mantener estructuras de datos necesarias para implementar modelos, y emplear programas avanzados de analisis y metodos estadisticos para preparar datos en modelos predictivos y prescriptivos.
La planificacion o Backlog de iniciativas analíticas del Manual de Gobierno de Modelos Analíticos de Auditoría es un documento vivo que se va retroalimentando a partir de diferentes canales: Ideation Workshops, que se programan durante el año entre el equipo de auditores y la unidad de analytics con el objetivo de recabar pain points durante el trabajo de auditoría, y requerimientos ad-hoc de cada gerencia de negocio al finalizar sus revisiones de auditoría, además este Backlog es gestionado por el Sub Gerente de la Unidad de Advanced Analytics y Monitoreo y validado por los Líderes de cada Team de Auditoría. 
La priorización de iniciativas analíticas indicadas en el Manual de Gobierno de Modelos Analíticos de Auditoría indica que para el año en curso se define previa coordinación con la Gerencia de Área de Auditoría de Riesgos, teniendo en cuenta factores de Complejidad e Impacto (Valor agregado), primero la Complejidad se considera mediante el Nivel de Analytics, las Técnicas a utilizar, la Disponibilidad de la información, la Definición del caso de uso, la Magnitud de cambios en el proceso y el Nivel de dependencia con otros proyectos, segundo se considera el Impacto (Valor Agregado) y se evalúa considerando el Nivel de simplificación operativa, el Alcance, la Monetización, el Nivel de cobertura y reducción de riesgos, la Mejora de un proceso clave y el Alineamiento estratégico. 
El Manual de Gobierno de Modelos Analíticos de Auditoría indica que la asesoría o soporte en trabajos adicionales al plan de iniciativas analíticas indica que este debe se solicitado por el líder de cada Team o Supervisor de la Auditoría en proceso, para ello el equipo de Analytics brindará el soporte requerido de acuerdo con el capacity de atención que maneje, en caso no se cuente con capacity se deberá de re-definir prioridades con el Líder de Team y el Gerente de Área.
La metodología descrita el Manual de Gobierno de Modelos Analíticos de Auditoría  y es aplicada en el el área de Auditoria Analítica Continua se enfoca en el análisis de información basada en ciencia de datos y  tiene como alcance garantizar el adecuado desarrollo de los proyectos analíticos, este va acompañando desde el planteamiento de la necesidad del negocio hasta su despliegue, con el objetivo de salvaguardar su importancia en el tiempo, además esta metodología busca un flujo de trabajo continuo, en el cual cada etapa de los proyectos converse y encajen perfectamente con la etapa siguiente logrando así un método de trabajo optimizado, eficiente, transversal a la institución y con capacidad de resiliencia ante los problemas que se presentan, por último se ha propuesto una metodología en ciencia de datos que se asemeja a CRISP y SEMMA, pero destaca por incluir prácticas actuales como el manejo de grandes volúmenes de datos, análisis de texto en modelado predictivo y automatización de procesos.
La metodología del Manual de Gobierno de Modelos Analíticos de Auditoría  y es aplicada en el el área de Auditoria Analítica Continua consiste en el análisis de información basada en ciencia de datos y  tiene como alcance garantizar el adecuado desarrollo de los proyectos analíticos, este va acompañando desde el planteamiento de la necesidad del negocio hasta su despliegue, con el objetivo de salvaguardar su importancia en el tiempo, además esta metodología busca un flujo de trabajo continuo, en el cual cada etapa de los proyectos converse y encajen perfectamente con la etapa siguiente logrando así un método de trabajo optimizado, eficiente, transversal a la institución y con capacidad de resiliencia ante los problemas que se presentan, por último se ha propuesto una metodología en ciencia de datos que se asemeja a CRISP y SEMMA, pero destaca por incluir prácticas actuales como el manejo de grandes volúmenes de datos, análisis de texto en modelado predictivo y automatización de procesos.
Los pasos de la metodología descrita en el Manual de Gobiernos de Modelos Analíticos de Auditoría son: (1) la comprensión del negocio, (2) enfoque analítico , Check Point A, (3) Solicitud de datos, Check Point B, (4)Recolección y Validación de los datos, (5) Comprensión de los datos, (6) Evaluación de los datos, (7) Preparación del modelo de datos, (8) Modelamiento,- Check Point C (9) Evaluación de resultados, (10) 5.10. Prueba piloto de campo, (11) Implementación, Check Point D, (12) Retroalimentación.
La fase de comprensión del negocio en la metodología descrita en el Manual de Gobierno de Modelos Analíticos de Auditoría indica que El flujo de desarrollo del modelo analítico comienza con la comprensión del negocio, donde los dueños y expertos definen el problema, objetivos y requisitos desde la perspectiva del negocio,esta etapa es fundamental para el éxito del proyecto, requiriendo la participación de patrocinadores y un dueño del producto para brindar conocimientos especializados y garantizar el avance adecuado; durante este proceso, el Data Scientist Leader y el Business Expert recopilan información relevante, mientras que el Data Engineer se encarga de obtener datos de fuentes, asegurando su consistencia y accesibilidad.
La fase de enfoque analítico en la metodología descrita en el Manual de Gobierno de Modelos Analíticos de Auditoría consiste en qye una vez que se ha definido claramente el problema, el equipo de Analytics puede establecer el enfoque analítico para resolverlo, expresando el problema en términos de técnicas estadísticas y de aprendizaje automático. Esto permite al Data Scientist identificar las técnicas más adecuadas para alcanzar el resultado deseado, como la creación, prueba e implementación de un modelo de clasificación para predecir respuestas binarias. En esta etapa, se utiliza la Ficha del proyecto analítico para documentar el alcance, tiempo y equipo de desarrollo, y se recomienda a los expertos del negocio recolectar una muestra representativa para evaluar el modelo analítico en el futuro.
La subfase de Check Point A en la metodología descrita en el Manual de Gobierno de Modelos Analíticos de Auditoría indica que  se convocarán a los Gerentes de cada área involucrada en el desarrollo del producto, para que aprueben el enfoque analítico planteado por el equipo Analytics. Si el Product Owner y los Gerentes involucrados aprueban el enfoque, el equipo Analytics podrá avanzar a la siguiente etapa. Si no lo aprueban, se deberá realizar una mejor comprensión de las necesidades del negocio.
La fase de solicitud de los datos en la metodología descrita en el Manual de Gobierno de Modelos Analíticos de Auditoría indica que el alcance del análisis seleccionado define los requisitos de datos necesarios, incluyendo formatos, contenido y representaciones específicas para los métodos analíticos a utilizar. En colaboración con los expertos del negocio, el Data Scientist elabora una lista de posibles variables para abordar el problema, la cual se dirige al Data Engineer. Estos requerimientos se documentan en la Ficha de Requerimiento Datos (Anexo II), asegurando una base sólida para la recopilación y preparación de datos necesarios para el análisis.
La subfase de Check Point B en la metodología descrita en el Manual de Gobierno de Modelos Analíticos de Auditoría indica que El Data Scientist Leader y el Business Expert validan la periodicidad de las variables, las transformaciones necesarias y la lógica de construcción de las variables. Una vez que estos profesionales aprueban estos aspectos, el Data Engineer comenzará los trabajos de recolección de datos.
La fase de Recolección y Validación de los datos en la metodología descrita en el Manual de Gobierno de Modelos Analíticos de Auditoría consiste en que una vez aprobada la lista de requerimientos de datos, el Data Engineer inicia la recolección identificando y recopilando recursos de datos relevantes (estructurados, no estructurados y semiestructurados) según lo especificado en la Ficha de Requerimiento Datos. Posteriormente, se lleva a cabo la depuración y/o imputación de los datos en colaboración con el equipo Analytics.
La fase de Comprensión de los datos en la metodología descrita en el Manual de Gobierno de Modelos Analíticos de Auditoría consiste en que El Data Scientist realiza un análisis exploratorio de las variables para comprender su significancia e importancia en la solución del problema. Las personas del área de negocio apoyan en esta etapa. Después de la recolección de los datos originales, el Data Scientist generalmente utiliza estadísticas descriptivas y técnicas de visualización para comprender el contenido de los datos, evaluar la calidad de los datos y revelar los conocimientos iniciales sobre los datos (mínimo, máximo, valores nulos, dispersiones). En algunas ocasiones podría ser necesario recopilar datos adicionales para llenar las brechas de información, esto en coordinación con los expertos del negocio y el dueño del producto.
La fase de Evaluación de los datos  en la metodología descrita en el Manual de Gobierno de Modelos Analíticos de Auditoría funciona como una validación de la calidad y consistencia de los datos, el business expert (experto del negocio) busca que los resultados del análisis exploratorio sean coherentes y concordantes con el conocimiento que se tiene del negocio.
La etapa de Preparación del modelo de datos  en la metodología descrita en el Manual de Gobierno de Modelos Analíticos de Auditoría es fundamental en un proyecto analítico, ya que abarca todas las actividades necesarias para construir el conjunto de datos que se utilizará en la fase de modelado posterior. Este proceso suele ser uno de los más lentos. Las tareas clave en la preparación de datos incluyen la limpieza de datos (tratando valores faltantes o inválidos, eliminando duplicados y asegurando el formato correcto), la integración de datos de diversas fuentes (archivos, tablas, plataformas) y la transformación de los datos en variables más útiles. Todo esto se realiza con el propósito de crear un tablón analítico que sea sólido y confiable para el análisis posterior.
La fase de modelamiento  en la metodología descrita en el Manual de Gobierno de Modelos Analíticos de Auditoría se centra en el desarrollo de modelos predictivos o descriptivos según el enfoque analítico definido previamente, este proceso es altamente iterativo, permitiendo ajustar la preparación de datos y la especificación del modelo a medida que las organizaciones adquieren conocimientos intermedios, se basa en pruebas de ensayo error, y para un objetivo determinado, el Data Scientist debe probar varios algoritmos con sus respectivos parámetros para encontrar el mejor modelo., la naturaleza de los datos ayuda a elegir la técnica y el algoritmo más adecuado, con el propósito de aumentar la predicción del modelo y tener resultados accionables o de valor para el negocio y una vez definido y evaluado el modelo final, el Data Scientist debe elaborar un informe de todo el modelamiento con la finalidad que sea posible la reproducción e implementación de este.
La subfase de Check Point C en la metodología descrita en el Manual de Gobierno de Modelos Analíticos de Auditoría indica: El Project Manager verificará que se haya cumplido los procedimientos mínimos de modelamiento, incluyendo la limpieza, depuración, imputación, transformación de variables, correlaciones, fijación de semilla, selección de variables, muestra de entrenamiento y validación, prueba de al menos 2 algoritmos, y verificación de sus indicadores de eficiencia.
La fase de evaluación de resultados descrita en el Manual de Gobierno de Modelos Analíticos de Auditoría indica que los expertos del negocio evalúan las variables finales y los resultados del modelo analítico. Los proyectos seleccionados suelen tener alternativas de solución clásica o existente, por lo que los modelos elaborados deben igualar en primera instancia los resultados de la solución existente antes de mejorarlos. Este proceso de evaluación, conocido como AB testing, implica poner a prueba el producto desarrollado con el existente mediante dos muestras espejos con características similares para medir los resultados.
La fase de Prueba de piloto de campo en la metodología descrita en el Manual de Gobierno de Modelos Analíticos de Auditoría indica que una vez aprobada la evaluación de los resultados, se elege una muestra para ser evaluada en una prueba de campo (Auditoria), el resultado del modelo analítico en la prueba de campo será informado a los usuarios finales del producto, los cuales pueden ser los auditores y/o auditados, también toda evaluación o reunión quedará registrada en un acta de reunión custodiada por el Data Scientist Leader, es posible encontrar variables no consideradas en el análisis e identificar falsos positivos, es en esta etapa el dueño del producto decidirá si se despliega el producto desarrollado o se reentrena hasta conseguir resultados satisfactorios, una vez observado y aprobado los resultados del modelo, el Data Scientist debe elaborar un Manual Metodológico con todo el detalle de la construcción del modelo y enviarlo al Data Engineer para el  despliegue.
La fase de implementación en la metodología descrita en el Manual de Gobierno de Modelos Analíticos de Auditoría consiste en que una vez que se ha creado un modelo satisfactorio y se cuenta con la aprobación de los propietarios del producto, se procede a implementarlo en el entorno de producción. Esta implementación suele ser inicialmente limitada, permitiendo una evaluación exhaustiva de su rendimiento. Puede variar desde la creación de un panel con recomendaciones hasta la integración del modelo en flujos de trabajo complejos, como sistemas transaccionales, junto con un proceso de validación administrado por una aplicación personalizada.
La subfase de Check Point D en la metodología descrita en el Manual de Gobierno de Modelos Analíticos de Auditoría indica: El Data Scientist Leader es responsable de asegurar que las condiciones de despliegue sean óptimas y que el producto final cumpla con las características y estándares requeridos por el propietario del producto. Una vez elegido el camino, ambiente de producción y desarrollado el producto, el Data Engineer debe elaborar un Manual de Implementación para suplir posibles cambios futuros. Como parte de la validación, el Data Scientist Leader debe comprobar mediante una muestra que los resultados (score de riesgo, predicción o clúster de pertenencia) del despliegue sean iguales a los obtenidos durante el desarrollo.
La fase de retroalimentacion en la metodología descrita en el Manual de Gobierno de Modelos Analíticos de Auditoría indica que para mejorar un modelo implementado, el equipo Analytics recopila los resultados del campo y recibe retroalimentación sobre su rendimiento y impacto en la población objetivo. Esta retroalimentación puede incluir índices de respuesta a campañas promocionales dirigidas a grupos identificados por el modelo. Analizar esta retroalimentación permite al Data Scientist ajustar el modelo para aumentar su precisión y utilidad. Automatizar parte o la totalidad de los pasos de obtención de retroalimentación, evaluación, ajuste y reimplementación del modelo agiliza el proceso de actualización y mejora los resultados.
Los anexos descritos en el Manual de Gobierno de Modelos Analíticos de Auditoría son Anexo 1: Ficha del Proyecto Analítico, Anexo 2: Ficha de Requerimiento de Datos,Anexo 3: Manual Metodológico ,Anexo 4: Proceso de Despliegue de Modelo Analítico,Anexo 5: Requerimiento de Hardware, Anexo 6: Manual Implementación 
El objetivo del 23.2.2 Manual de generación de pruebas de auditoría con python es el siguiente: describir los procedimientos requeridos para que se pueda desarrollar analíticas avanzadas en Python de manera correcta y poder tener una trazabilidad que sustente los análisis desarrollado en Python a través del entorno de Jupyter Notebook de Anaconda, asimsmo, se detallan los documentos mínimos que el auditor deberá registrar en la plataforma core de Auditoría (Team Mate o RSA) para evidenciar la correcta utilización de esta nueva herramienta de análisis de datos. 
Los objetivos específicos del 23.2.2 Manual de generación de pruebas de auditoría con python son los siguientes: (1) Democratizar el desarrollo de la analítica avanzada de Auditoría aplicando Data Analytics, (2) Impulsar el uso masivo de los datos para realizar pruebas de auditoría de mayor cobertura (3) Reutilizar los scripts desarrollados en otras evaluaciones de auditoría y (4) Almacenar y custodiar las pruebas analíticas desarrolladas en la División de Auditoría.
El uso de python según el 23.2.2 Manual de generación de pruebas de auditoría con Python indica que es un lenguaje open source o de código abierto, por lo que no hay que pagar ninguna licencia para utilizarlo. Forma parte del repositorio de Estándares Tecnológicos del BCP como herramienta vigente.
El Framework del Notebook según el  23.2.2 Manual de generación de pruebas de auditoría con Python el notebook de la prueba de auditoría debe tener el siguiente encabezado como parte del Framework, con el objetivo de detallar el objetivo del análisis y la auditoría a la que está relacionada.
Los lineamientos para el ambiente de desarrollo especificados en el 23.2.2 Manual de generación de pruebas de auditoría con Python se dividen en dos puntos importantes: (1) Ruta Oficial (Ambiente de Desarrollo) y (2) Carpetas a utilizar.
La ruta oficial  según el 23.2.2 Manual de generación de pruebas de auditoría con Python indica que se debe trabajar en el servidor de desarrollo autogestionado PFILEP12, donde se guardarán las pruebas realizadas en Python, inputs y resultados finales tales como: .xslx, .csv, .ipynb, entre otros; la ruta oficial es la siguiente: Ruta: \\pfilep12\Audit_RecursosCompartidos\Compartido_AudDataAnalytics
Las carpetas a utilizar según en el 23.2.2 Manual de generación de pruebas de auditoría con Python estan dentro de la carpeta de cada Team donde se encontrará una carpeta denominada “PROYECTO CDS – PYTHON”, aquí se encontrarán los proyectos de auditoría bajo la denominación ANXX Nombre_Proyecto_Auditoría, también debemos ingresar a la carpeta con el nombre de proyecto de auditoría seleccionado y crearás una nueva carpeta donde se almacenará la prueba de Python con el siguiente formato de nombre: PYXXYY_NombrePrueba.
La carpeta Notebooks según el 23.2.2 Manual de generación de pruebas de auditoría con Python almacenarán sólo los Notebooks (Extensión .ipynb) que se generen en la aplicación Jupyter Notebook de Anaconda.
La carpeta Fuentes según el 23.2.2 Manual de generación de pruebas de auditoría con Python almacenará todos los inputs utilizados en el análisis: (.xlsx, .csv, .txt ), scripts SQL/PLSQL, archivos planos solicitados a otras unidades, Anexo 2.
La carpeta Resultados según el 23.2.2 Manual de generación de pruebas de auditoría con Python se guardarán los archivos generados (.xlsx, .txt, .csv) por el análisis ejecutado en el noteboo, se debe considerar los lineamientos del Manual de Seguridad indicados en este documento.
Los Lineamientos del Desarrollo de Pruebas según el 23.2.2 Manual de generación de pruebas de auditoría con Python están divididos en cuatro puntos importantes: (1) Framework del Notebook, (2) Estructura de los pasos a desarrollar, (3) Registro de Fuentes y (4) Resultados.
El Framework del notebook de la prueba de auditoría según el 23.2.2 Manual de generación de pruebas de auditoría con Python se encuentra especificado en el Anexo 1 del presente manual, con el objetivo de detallar el objetivo del análisis y la auditoría a la que está relacionada.
La estructura de pasos a desarrollar según el 23.2.2 Manual de generación de pruebas de auditoría con Python tiene el objetivo de asegurar un adecuado análisis descriptivo durante el desarrollo de las pruebas, este tieen cuatro puntos importantes: (0) Importación de librerías, (1) Definición del problema, (2) Carga y limpieza de datos, (3) Análisis exploratorio de Datos (EDA) y (4) Conclusiones; por último la estructura de pasos están detallados en el Anexo 1 del presente manual.
El Registro de Fuentes especificada 23.2.2 Manual de generación de pruebas de auditoría con Python indica que es que es necesario registrar las fuentes en el Anexo 2 del manual, mapeando cada fuente con su script de extracción, detallando si provienen de una base de datos o son archivos planos, además se deben incluir las variables con su descripción en el Notebook, evitando usar variables pretransformadas y asegurándose de que los campos estén completos para no afectar el indicador de pruebas de auditoría digitalizadas en Python.
Los Resultados especificados en el 23.2.2 Manual de generación de pruebas de auditoría con Python indica que una vez culminado el desarrollo del notebook, obteniendo las conclusiones respectivas, se procede a exportar la información en formato (.txt, .csv o xlsx) en la carpeta “Resultados” y no se debe almacenar datos DAC
El Registro de Pruebas según el 23.2.2 Manual de generación de pruebas de auditoría con Python indica que el Auditor debe registrar el nuevo CAAT en el Inventario centralizado de pruebas de auditoría al finalizar el desarrollo de la prueba, además el registro en el inventario es vital para iniciar el flujo de validación por parte de los Chapters Data Analytics Fundamentals y Data Science, finalmente a partir de este registro, se medirá el indicador de pruebas de auditoría digitalizadas en Python por auditor.
Los Lineamientos de Seguridad según el 23.2.2 Manual de generación de pruebas de auditoría con Python establecen: al trabajar en el desarrollo de la prueba de auditoría en Python, no debe usar datos DAC como campos claves para unir o relacionar tablas, en su reemplazo deberás utilizar las llaves subrogadas (sustitutas). Las bases de datos de SQL en el servidor PTEAMSQLD01 deben estar asociadas a un proyecto específico y solo se pueden crear bases de prueba temporales sin datos DAC (especificados en el manual), además los campos Restringidos pero no DAC (CIC del cliente, Código SBS, y Matrícula del Colaborador) deben manejarse con precaución, ya que pueden exponer información sensible si se relacionan con otros campos.
El flujo de validación del desarrollo según el 23.2.2 Manual de generación de pruebas de auditoría con Python establecen describe el proceso (especificados en el manual) para validar y custodiar pruebas de auditoría en Python, proporcionando orientación en caso de problemas durante el desarrollo y asesoramiento para su resolución. El equipo de QA revisará muestralmente las pruebas finalizadas.
Los lineamientos de documentación según el 23.2.2 Manual de generación de pruebas de auditoría con Python indica que todas las pruebas de auditoría que involucren Data Analytics deben tener una marca en el TeamMate o RSA, además la documentación de las pruebas desarrolladas debe estar alineada con el Manual de Auditoría Interna (Anexo 26 – Manual de TeamMate) y debe incluir el Anexo 2.xlsx de las fuentes utilizadas y el Notebook de Jupyter con el análisis realizado. Los Notebooks deben seguir los lineamientos de desarrollo descritos en el manual y pueden ser auditados por el equipo de QA (Anexo 23.2.4 Manual de buenas prácticas para almacenamiento de pruebas asistidas por computador). 
El alcance del Manual de Gobierno Soluciones de Data - Automatización es para distribución de los interesados y define los principales puntos a considerar cuando se desarrolle un proyecto de Automatización, esto con la finalidad de implementar soluciones de Data, que agreguen valor a la función de auditoría.
